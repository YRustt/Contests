{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TINKOFF: https://boosters.pro/champ_3?success=0#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "import math\n",
    "\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, header=0, sep=';', encoding='pt154')\n",
    "    data = data.rename(index=str, columns={'client_id': '_ID_', 'open_acount_flg': '_VAL_'})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = read_data('../data/credit_train.csv')\n",
    "test = read_data('../data/credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_ID_</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>job_position</th>\n",
       "      <th>credit_sum</th>\n",
       "      <th>credit_month</th>\n",
       "      <th>tariff_id</th>\n",
       "      <th>score_shk</th>\n",
       "      <th>education</th>\n",
       "      <th>living_region</th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>credit_count</th>\n",
       "      <th>overdue_credit_count</th>\n",
       "      <th>open_account_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>MAR</td>\n",
       "      <td>UMN</td>\n",
       "      <td>59998,00</td>\n",
       "      <td>10</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0,770249</td>\n",
       "      <td>GRD</td>\n",
       "      <td>КРАСНОДАРСКИЙ КРАЙ</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>MAR</td>\n",
       "      <td>UMN</td>\n",
       "      <td>10889,00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0,248514</td>\n",
       "      <td>GRD</td>\n",
       "      <td>МОСКВА</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>MAR</td>\n",
       "      <td>SPC</td>\n",
       "      <td>10728,00</td>\n",
       "      <td>12</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0,459589</td>\n",
       "      <td>SCH</td>\n",
       "      <td>ОБЛ САРАТОВСКАЯ</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>DIV</td>\n",
       "      <td>SPC</td>\n",
       "      <td>12009,09</td>\n",
       "      <td>12</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0,362536</td>\n",
       "      <td>GRD</td>\n",
       "      <td>ОБЛ ВОЛГОГРАДСКАЯ</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>MAR</td>\n",
       "      <td>SPC</td>\n",
       "      <td>16908,89</td>\n",
       "      <td>10</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0,421385</td>\n",
       "      <td>SCH</td>\n",
       "      <td>ЧЕЛЯБИНСКАЯ ОБЛАСТЬ</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _ID_ gender  age marital_status job_position credit_sum  credit_month  \\\n",
       "0     1      M   48            MAR          UMN   59998,00            10   \n",
       "1     2      F   28            MAR          UMN   10889,00             6   \n",
       "2     3      M   32            MAR          SPC   10728,00            12   \n",
       "3     4      F   27            DIV          SPC   12009,09            12   \n",
       "4     5      M   45            MAR          SPC   16908,89            10   \n",
       "\n",
       "   tariff_id score_shk education        living_region  monthly_income  \\\n",
       "0        1.6  0,770249       GRD   КРАСНОДАРСКИЙ КРАЙ         30000.0   \n",
       "1        1.1  0,248514       GRD               МОСКВА         43000.0   \n",
       "2        1.1  0,459589       SCH      ОБЛ САРАТОВСКАЯ         23000.0   \n",
       "3        1.1  0,362536       GRD    ОБЛ ВОЛГОГРАДСКАЯ         17000.0   \n",
       "4        1.1  0,421385       SCH  ЧЕЛЯБИНСКАЯ ОБЛАСТЬ         25000.0   \n",
       "\n",
       "   credit_count  overdue_credit_count  open_account_flg  \n",
       "0           1.0                   1.0                 0  \n",
       "1           2.0                   0.0                 0  \n",
       "2           5.0                   0.0                 0  \n",
       "3           2.0                   0.0                 0  \n",
       "4           1.0                   0.0                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_names = []\n",
    "\n",
    "def parse_living_region(data):\n",
    "    def get_good_name(s_name):\n",
    "        if s_name.find('КРАЙ') != -1:\n",
    "            tokens = [x for x in s_name.split() for x in x.split('.')]\n",
    "            good_name = list(filter(lambda x: x != '' and x != 'КРАЙ', tokens))\n",
    "            return good_name[0]\n",
    "        if s_name.find('АО') != -1:\n",
    "            tokens = [x for x in s_name.split() for x in x.split('.')]\n",
    "            good_name = list(filter(lambda x: x != '' and x.find('АО') == -1, tokens))\n",
    "            return good_name[0]\n",
    "        if s_name.find('ОБЛ') != -1:\n",
    "            tokens = [x for x in s_name.split() for x in x.split('.')]\n",
    "            good_name = list(filter(lambda x: x != '' and x != 'ОБЛ' and x != 'ОБЛАСТЬ', tokens))\n",
    "            return good_name[-1]\n",
    "        if s_name.find('РЕСП') != -1:\n",
    "            tokens = [x for x in s_name.split() for x in x.split('.')]\n",
    "            good_name = list(filter(lambda x: x != '' and x != 'РЕСП' and x != 'РЕСПУБЛИКА', tokens))\n",
    "            return good_name[0]\n",
    "        if len(s_name.split()) == 1 and len(s_name.split('.')) == 1:\n",
    "            return s_name\n",
    "        if s_name.find('МОСКВА') != -1:\n",
    "            return 'МОСКВА'\n",
    "        if s_name.find('ПЕТЕРБУРГ'):\n",
    "            return 'САНКТ-ПЕТЕРБУРГ'\n",
    "        if s_name.find('АВТОНОМНЫЙ'):\n",
    "            return s_name.split()[0]\n",
    "        if s_name.find('ЕВРЕЙ'):\n",
    "            return 'ЕВРЕЙСКАЯ'\n",
    "        if s_name.find('ДАЛЬНИЙ'):\n",
    "            return 'ДАЛЬНИЙ ВОСТОК'\n",
    "        if s_name.find('ФЕДЕРАЛЬНЫЙ'):\n",
    "            return s_name.split()[0]\n",
    "        bad_names.append(s_name)\n",
    "        return np.nan\n",
    "        \n",
    "    return [get_good_name(x) if x is not np.nan else 'BAD NAME' for x in data]\n",
    "\n",
    "\n",
    "def reduction_living_region(data):\n",
    "    def get_good_name(s_name):\n",
    "        if s_name == 'BAD NAME':\n",
    "            bad_names.append(np.nan)\n",
    "        if s_name == '74':\n",
    "            return 'ЧЕЛЯБИН'\n",
    "        if s_name == '98':\n",
    "            return 'САНКТ-ПЕТЕРБУРГ'\n",
    "        if s_name == 'РЕСПУБЛИКАТАТАРСТАН':\n",
    "            return 'ТАТАРСТАН'\n",
    "        if s_name == 'МОСКВОСКАЯ':\n",
    "            return 'МОСКОВ'\n",
    "        if s_name == 'РОССИЯ':\n",
    "            bad_names.append(s_name)\n",
    "            return 'BAD NAME'\n",
    "        if s_name == 'КАМЧАТС??ИЙ':\n",
    "            return 'КАМЧАТ'\n",
    "        if s_name == 'ХАНТЫ-МАНСИЙСКИЙ-ЮГРА':\n",
    "            return 'ХАНТЫ-МАНСИЙ' \n",
    "        if s_name.find('СКИЙ') != -1 or s_name.find('СКАЯ') != -1:\n",
    "            return s_name[:-4]\n",
    "        return s_name\n",
    "    \n",
    "    return [get_good_name(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAD NAME', 'АДЫГЕЯ', 'АЛТАЙ', 'АМУР', 'АРХАНГЕЛЬ', 'АСТРАХАН', 'БАШКОРТОСТАН', 'БЕЛГОРОД', 'БРЯН', 'БУРЯТИЯ', 'ВЛАДИМИР', 'ВОЛГОГРАД', 'ВОЛОГОД', 'ВОРОНЕЖ', 'ГОРЬКОВ', 'ДАГЕСТАН', 'ЕВРЕЙ', 'ЗАБАЙКАЛЬ', 'ИВАНОВ', 'ИНГУШЕТИЯ', 'ИРКУТ', 'КАБАРДИНО-БАЛКАР', 'КАЛИНИНГРАД', 'КАЛМЫКИЯ', 'КАЛУЖ', 'КАМЧАТ', 'КАРАЧАЕВО-ЧЕРКЕС', 'КАРЕЛИЯ', 'КЕМЕРОВ', 'КИРОВ', 'КОМИ', 'КОСТРОМ', 'КРАСНОДАР', 'КРАСНОЯР', 'КУР', 'КУРГАН', 'ЛЕНИНГРАД', 'ЛИПЕЦКАЯ', 'МАГАДАН', 'МАРИЙ', 'МОРДОВИЯ', 'МОСКВА', 'МОСКОВ', 'МУРМАН', 'НЕНЕЦКИЙ', 'НИЖЕГОРОД', 'НОВГОРОД', 'НОВОСИБИР', 'ОМ', 'ОРЁЛ', 'ОРЕНБУРГ', 'ОРЛОВ', 'ПЕНЗЕН', 'ПЕРМ', 'ПРИМОР', 'ПСКОВ', 'РОСТОВ', 'РЯЗАН', 'САМАР', 'САНКТ-ПЕТЕРБУРГ', 'САРАТОВ', 'САХА', 'САХАЛИН', 'СВЕРДЛОВ', 'СЕВЕРНАЯ', 'СМОЛЕН', 'СТАВРОПОЛЬ', 'ТАМБОВ', 'ТАТАРСТАН', 'ТВЕР', 'ТОМ', 'ТУЛЬ', 'ТЫВА', 'ТЮМЕН', 'УДМУРТ', 'УЛЬЯНОВ', 'ХАБАРОВ', 'ХАКАСИЯ', 'ХАНТЫ-МАНСИЙ', 'ЧЕЛЯБИН', 'ЧЕЧЕН', 'ЧИТИН', 'ЧУВАШ', 'ЧУВАШИЯ', 'ЧУКОТ', 'ЭВЕНКИЙ', 'ЯМАЛО-НЕНЕЦКИЙ', 'ЯРОСЛАВ'] 88\n",
      "['nan' 'РОССИЯ'] 310\n"
     ]
    }
   ],
   "source": [
    "train_living_region = \\\n",
    "            np.unique(reduction_living_region(parse_living_region([s_name for s_name in train['living_region']])))\n",
    "test_living_region = \\\n",
    "            np.unique(reduction_living_region(parse_living_region([s_name for s_name in test['living_region']])))\n",
    "union_living_region = list(set(train_living_region).union(set(test_living_region)))\n",
    "union_living_region.sort()\n",
    "print(union_living_region, len(union_living_region))\n",
    "print(np.unique(bad_names), len(bad_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIU', 'ONB', 'PNA', 'PNI', 'PNV'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train['job_position'].unique()) \\\n",
    "- set(['SPC', 'DIR', 'HSK', 'INV', 'WOI', 'WRK', 'ATP', 'WRP', 'UMN', 'NOR', 'PNS', 'BIS', 'INP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, train):\n",
    "        self._train = train\n",
    "    \n",
    "    def get_gender_feature(self, data):\n",
    "        poss = ['F', 'M']\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(s_gender)] for s_gender in self._train.gender])\n",
    "        return enc.transform([[poss.index(s_gender)] for s_gender in data.gender]).toarray()\n",
    "    \n",
    "    def get_age_feature(self, data):\n",
    "        return data.age.values.reshape((-1, 1))\n",
    "    \n",
    "    def get_marital_status_feature(self, data):\n",
    "        poss = ['UNM', 'DIV', 'MAR', 'WID', 'CIV']\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(s_marital_status)] for s_marital_status in self._train.marital_status])\n",
    "        return enc.transform([[poss.index(s_marital_status)] for s_marital_status in data.marital_status]).toarray()\n",
    "    \n",
    "    def get_job_position_feature(self, data):\n",
    "        poss = ['SPC', 'DIR', 'HSK', 'INV', 'WOI', 'WRK', 'ATP', 'WRP', 'UMN', 'NOR', 'PNS', 'BIS', 'INP',\n",
    "                'BIU', 'ONB', 'PNA', 'PNI', 'PNV']\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(s_job_position)] for s_job_position in self._train.job_position])\n",
    "        return enc.transform([[poss.index(s_job_position)] for s_job_position in data.job_position]).toarray()\n",
    "    \n",
    "    def get_credit_sum_feature(self, data):\n",
    "        return np.array([[round(float(s_credit_sum.replace(',', '.')) / 1000)] \n",
    "                         for s_credit_sum in data.credit_sum])\n",
    "    \n",
    "    def get_credit_month_feature(self, data):\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[credit_month] for credit_month in self._train.credit_month])\n",
    "        return enc.transform([[credit_month] for credit_month in data.credit_month]).toarray()\n",
    "    \n",
    "    def get_tariff_id_feature(self, data):\n",
    "        poss = list(np.unique(self._train.tariff_id))\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(tariff_id)] for tariff_id in poss])\n",
    "        return enc.transform([[poss.index(tariff_id)] for tariff_id in data.tariff_id]).toarray()\n",
    "    \n",
    "    def get_score_shk_feature(self, data):\n",
    "        return np.array([[float(s_score_shk.replace(',', '.'))] for s_score_shk in data['score_shk']])\n",
    "    \n",
    "    def get_education_feature(self, data):\n",
    "        poss = ['SCH', 'UGR', 'GRD', 'PGR', 'ACD']\n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(s_education)] for s_education in self._train.education])\n",
    "        return enc.transform([[poss.index(s_education)] for s_education in data.education]).toarray()\n",
    "    \n",
    "    def get_living_region_feature(self, data):        \n",
    "        tr_liv_reg = reduction_living_region(parse_living_region([s_name for s_name in self._train.living_region]))\n",
    "        da_liv_reg = reduction_living_region(parse_living_region([s_name for s_name in data.living_region]))\n",
    "        poss = list(np.unique(tr_liv_reg))\n",
    "        \n",
    "        enc = preprocessing.OneHotEncoder()\n",
    "        enc.fit([[poss.index(s_tr_liv_reg)] for s_tr_liv_reg in tr_liv_reg])\n",
    "        da_liv_reg = enc.transform([[poss.index(s_living_region)]\n",
    "                                     for s_living_region in da_liv_reg]).toarray()\n",
    "        tr_liv_reg = enc.transform([[poss.index(s_living_region)]\n",
    "                                     for s_living_region in tr_liv_reg]).toarray()\n",
    "        pca = decomposition.PCA(8)\n",
    "        pca.fit(tr_liv_reg)\n",
    "        return pca.transform(da_liv_reg)\n",
    "        \n",
    "    \n",
    "    def get_monthly_income_feature(self, data):\n",
    "        monthly_incomes = data.monthly_income.fillna(data.monthly_income.mean()).apply(lambda x: np.round(x / 1000))\n",
    "        return monthly_incomes.values.reshape((-1, 1))\n",
    "    \n",
    "    def get_credit_count_feature(self, data):\n",
    "        credit_counts = data.credit_count.fillna(data.credit_count.mean())\n",
    "        return credit_counts.values.reshape((-1, 1))\n",
    "    \n",
    "    def get_overdue_credit_count_feature(self, data):\n",
    "        overdue_credit_counts = data.overdue_credit_count.fillna(data.overdue_credit_count.mean())\n",
    "        return overdue_credit_counts.values.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_features = Features(train)\n",
    "train_features = np.concatenate((make_features.get_gender_feature(train),\n",
    "                                 make_features.get_age_feature(train),\n",
    "                                 make_features.get_marital_status_feature(train),\n",
    "                                 make_features.get_job_position_feature(train),\n",
    "                                 make_features.get_credit_sum_feature(train),\n",
    "                                 make_features.get_credit_month_feature(train),\n",
    "                                 make_features.get_tariff_id_feature(train),\n",
    "                                 make_features.get_score_shk_feature(train),\n",
    "                                 make_features.get_education_feature(train),\n",
    "                                 make_features.get_living_region_feature(train),\n",
    "                                 make_features.get_monthly_income_feature(train),\n",
    "                                 make_features.get_credit_count_feature(train),\n",
    "                                 make_features.get_overdue_credit_count_feature(train)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = np.concatenate((make_features.get_gender_feature(test),\n",
    "                                make_features.get_age_feature(test),\n",
    "                                make_features.get_marital_status_feature(test),\n",
    "                                make_features.get_job_position_feature(test),\n",
    "                                make_features.get_credit_sum_feature(test),\n",
    "                                make_features.get_credit_month_feature(test),\n",
    "                                make_features.get_tariff_id_feature(test),\n",
    "                                make_features.get_score_shk_feature(test),\n",
    "                                make_features.get_education_feature(test),\n",
    "                                make_features.get_living_region_feature(test),\n",
    "                                make_features.get_monthly_income_feature(test),\n",
    "                                make_features.get_credit_count_feature(test),\n",
    "                                make_features.get_overdue_credit_count_feature(test)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=120, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA(120)\n",
    "pca.fit(train_features)\n",
    "t_train_features = pca.transform(train_features)\n",
    "t_test_features = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_features, train.open_account_flg,\n",
    "                                                                      test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119522, 107) (51224, 107) (91940, 107)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(model, param_grid, X_train, X_valid, y_train, y_valid, X_test):\n",
    "    est = model_selection.GridSearchCV(model, param_grid=param_grid, n_jobs=-1)\n",
    "    est.fit(X_train, y_train)\n",
    "    print(est.best_estimator_)\n",
    "    return est\n",
    "\n",
    "\n",
    "def estimate(est):\n",
    "    proba_train = est.predict_proba(X_train)\n",
    "    print(metrics.roc_auc_score(y_train, proba_train[:, 1]))\n",
    "\n",
    "    proba_valid = est.predict_proba(X_valid)\n",
    "    print(metrics.roc_auc_score(y_valid, proba_valid[:, 1]))\n",
    "\n",
    "    proba_test = est.predict_proba(X_test)\n",
    "    return proba_train[:, 1], proba_valid[:, 1], proba_test[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=30,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=380, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "est = model(ensemble.GradientBoostingClassifier(min_samples_leaf=30), \n",
    "            {'n_estimators': [i for i in range(300, 401, 20)]},\n",
    "            X_train, X_valid, y_train, y_valid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779200492863\n",
      "0.763781316104\n"
     ]
    }
   ],
   "source": [
    "gb_pred_train, gb_pred_valid, gb_pred_test = estimate(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=80, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rf_est = model(ensemble.RandomForestClassifier(min_samples_leaf=10), \n",
    "               {'n_estimators': [i for i in range(50, 401, 30)]},\n",
    "               X_train, X_valid, y_train, y_valid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860952776977\n",
      "0.755441472141\n"
     ]
    }
   ],
   "source": [
    "rf_pred_train, rf_pred_valid, rf_pred_test = estimate(rf_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.823910825414\n",
      "0.764645292232\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_train, gb_pred_train * 0.1 + rf_pred_train * 0.1))\n",
    "print(metrics.roc_auc_score(y_valid, gb_pred_valid * 0.1 + rf_pred_valid * 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     _ID_     _VAL_\n",
      "0  170747  0.072488\n",
      "1  170748  0.147013\n",
      "2  170749  0.235742\n",
      "3  170750  0.157034\n",
      "4  170751  0.099641\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(data={'_ID_': test._ID_, '_VAL_': gb_pred_test * 0.8 + rf_pred_test * 0.2}, \n",
    "                          index=test.index)\n",
    "prediction.to_csv('../data/prediction.csv', index=False)\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
