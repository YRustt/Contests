{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer, base_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = word2vec.KeyedVectors.load_word2vec_format('word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.data', sep='\\t')\n",
    "test = pd.read_csv('data/test.data', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.Tokens = [nltk.word_tokenize(sentence.replace('\\\\n', ' ')) for sentence in train.Text]\n",
    "test.Tokens = [nltk.word_tokenize(sentence.replace('\\\\n', ' ')) for sentence in test.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(tokens):\n",
    "    out = []\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            out.extend(model.word_vec(word))\n",
    "        except:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "def batch_generator(X, y, batch_size):\n",
    "    all_count, i = X.shape[0], 0\n",
    "    num_batchs = all_count // batch_size\n",
    "    shuffle_index = np.arange(all_count)\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    while True:\n",
    "        index_batch = shuffle_index[batch_size * i: batch_size * (i + 1)]\n",
    "        batch = np.array([get_features(tokens) for tokens in X[index_batch, :].Tokens])\n",
    "        X_batch = np.zeros((batch_size, 100000), dtype=type(batch[0][0]))\n",
    "        for i in range(batch_size):\n",
    "            X_batch[i, :len(batch)] = batch[i]\n",
    "        y_batch = y[index_batch,:]\n",
    "        \n",
    "        i += 1\n",
    "        yield (np.array(X_batch), y_batch)\n",
    "        if i == num_batchs:\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train.Tokens, test.Tokens\n",
    "y_train = np_utils.to_categorical(train.Sentiment, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(40000,))\n",
    "inp_norm = BatchNormalization(axis=1)(inp)\n",
    "\n",
    "outs = []\n",
    "for i in range(3):\n",
    "    hidden = Dense(512, init='he_uniform', W_regularizer=l2(0.0001), activation='relu')(inp_norm)\n",
    "    batch = BatchNormalization(axis=1)(hidden)\n",
    "    drop = Dropout(0.25)(batch)\n",
    "    hidden = Dense(128, init='he_uniform', W_regularizer=l2(0.0001), activation='relu')(batch)\n",
    "    batch = BatchNormalization(axis=1)(hidden)\n",
    "    drop = Dropout(0.25)(batch)\n",
    "    hidden = Dense(16, init='he_uniform', W_regularizer=l2(0.0001), activation='relu')(drop)\n",
    "    batch = BatchNormalization(axis=1)(hidden)\n",
    "    drop = Dropout(0.5)(batch)\n",
    "    out = Dense(6, init='glorot_uniform', W_regularizer=l2(0.0001), activation='softmax')(drop)\n",
    "    outs.append(out)\n",
    "\n",
    "out = merge(outs, mode='ave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1f60280459d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m model.fit_generator(generator=batch_generator(X_train, y_train, 1000), \n\u001b[0;32m----> 6\u001b[0;31m                     nb_epoch=10000, samples_per_epoch=50000, verbose=2)\n\u001b[0m",
      "\u001b[0;32m/opt/lab/anaconda/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                      \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m                                      str(generator_output))\n\u001b[0m\u001b[1;32m   1482\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/lab/anaconda/envs/python3/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/lab/anaconda/envs/python3/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/lab/anaconda/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\", line 409, in data_generator_task\n",
      "    generator_output = next(generator)\n",
      "  File \"<ipython-input-7-4f513c06e73d>\", line 11, in batch_generator\n",
      "    all_count, i = X.shape[0], 0\n",
      "AttributeError: 'list' object has no attribute 'shape'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=inp, output=out)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.fit_generator(generator=batch_generator(X_train, y_train, 1000), \n",
    "                    nb_epoch=10000, samples_per_epoch=50000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
