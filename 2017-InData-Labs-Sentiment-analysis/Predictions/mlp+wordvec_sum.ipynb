{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = word2vec.KeyedVectors.load_word2vec_format('../word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/spacy_train.csv')\n",
    "test = pd.read_csv('../data/spacy_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_features(tokens):\n",
    "    out = []\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            out.append(model.word_vec(word))\n",
    "        except:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "train_features = [np.sum(get_features(sentence.split()), axis=0) for sentence in train.Text]\n",
    "test_features = [np.sum(get_features(sentence.split()), axis=0) for sentence in test.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = np.array(train_features), np.array(test_features)\n",
    "y_train = train[['1', '2', '3', '4', '5']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(300,))\n",
    "inp_norm = BatchNormalization(axis=1)(inp)\n",
    "\n",
    "hidden = Dense(200, init='he_uniform', activation='sigmoid')(inp_norm)\n",
    "# batch = BatchNormalization(axis=1)(hidden)\n",
    "drop = Dropout(0.5)(hidden)\n",
    "hidden = Dense(200, init='he_uniform', activation='sigmoid')(drop)\n",
    "# batch = BatchNormalization(axis=1)(hidden)\n",
    "drop = Dropout(0.5)(hidden)\n",
    "out = Dense(5, init='glorot_uniform', activation='softmax')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 102,605.0\n",
      "Trainable params: 102,005.0\n",
      "Non-trainable params: 600.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input=inp, output=out)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68704 samples, validate on 33840 samples\n",
      "Epoch 1/5000\n",
      "0s - loss: 0.9501 - acc: 0.5752 - val_loss: 1.0069 - val_acc: 0.5470\n",
      "Epoch 2/5000\n",
      "0s - loss: 0.9506 - acc: 0.5743 - val_loss: 1.0079 - val_acc: 0.5475\n",
      "Epoch 3/5000\n",
      "0s - loss: 0.9503 - acc: 0.5743 - val_loss: 1.0070 - val_acc: 0.5467\n",
      "Epoch 4/5000\n",
      "0s - loss: 0.9499 - acc: 0.5749 - val_loss: 1.0071 - val_acc: 0.5472\n",
      "Epoch 5/5000\n",
      "0s - loss: 0.9502 - acc: 0.5742 - val_loss: 1.0076 - val_acc: 0.5484\n",
      "Epoch 6/5000\n",
      "0s - loss: 0.9494 - acc: 0.5744 - val_loss: 1.0073 - val_acc: 0.5472\n",
      "Epoch 7/5000\n",
      "0s - loss: 0.9498 - acc: 0.5755 - val_loss: 1.0075 - val_acc: 0.5473\n",
      "Epoch 8/5000\n",
      "0s - loss: 0.9503 - acc: 0.5738 - val_loss: 1.0078 - val_acc: 0.5473\n",
      "Epoch 9/5000\n",
      "0s - loss: 0.9493 - acc: 0.5760 - val_loss: 1.0072 - val_acc: 0.5473\n",
      "Epoch 10/5000\n",
      "0s - loss: 0.9474 - acc: 0.5749 - val_loss: 1.0074 - val_acc: 0.5476\n",
      "Epoch 11/5000\n",
      "0s - loss: 0.9498 - acc: 0.5732 - val_loss: 1.0072 - val_acc: 0.5478\n",
      "Epoch 12/5000\n",
      "0s - loss: 0.9489 - acc: 0.5744 - val_loss: 1.0072 - val_acc: 0.5475\n",
      "Epoch 13/5000\n",
      "0s - loss: 0.9487 - acc: 0.5749 - val_loss: 1.0076 - val_acc: 0.5477\n",
      "Epoch 14/5000\n",
      "0s - loss: 0.9497 - acc: 0.5758 - val_loss: 1.0073 - val_acc: 0.5480\n",
      "Epoch 15/5000\n",
      "0s - loss: 0.9491 - acc: 0.5731 - val_loss: 1.0071 - val_acc: 0.5482\n",
      "Epoch 16/5000\n",
      "0s - loss: 0.9493 - acc: 0.5764 - val_loss: 1.0078 - val_acc: 0.5485\n",
      "Epoch 17/5000\n",
      "0s - loss: 0.9498 - acc: 0.5752 - val_loss: 1.0074 - val_acc: 0.5482\n",
      "Epoch 18/5000\n",
      "0s - loss: 0.9470 - acc: 0.5744 - val_loss: 1.0077 - val_acc: 0.5478\n",
      "Epoch 19/5000\n",
      "0s - loss: 0.9485 - acc: 0.5735 - val_loss: 1.0077 - val_acc: 0.5483\n",
      "Epoch 20/5000\n",
      "0s - loss: 0.9469 - acc: 0.5742 - val_loss: 1.0076 - val_acc: 0.5473\n",
      "Epoch 21/5000\n",
      "0s - loss: 0.9475 - acc: 0.5749 - val_loss: 1.0076 - val_acc: 0.5480\n",
      "Epoch 22/5000\n",
      "0s - loss: 0.9484 - acc: 0.5739 - val_loss: 1.0078 - val_acc: 0.5481\n",
      "Epoch 23/5000\n",
      "0s - loss: 0.9480 - acc: 0.5771 - val_loss: 1.0076 - val_acc: 0.5480\n",
      "Epoch 24/5000\n",
      "0s - loss: 0.9466 - acc: 0.5740 - val_loss: 1.0077 - val_acc: 0.5477\n",
      "Epoch 25/5000\n",
      "0s - loss: 0.9478 - acc: 0.5772 - val_loss: 1.0079 - val_acc: 0.5476\n",
      "Epoch 26/5000\n",
      "0s - loss: 0.9488 - acc: 0.5740 - val_loss: 1.0075 - val_acc: 0.5474\n",
      "Epoch 27/5000\n",
      "0s - loss: 0.9475 - acc: 0.5753 - val_loss: 1.0076 - val_acc: 0.5475\n",
      "Epoch 28/5000\n",
      "0s - loss: 0.9456 - acc: 0.5743 - val_loss: 1.0075 - val_acc: 0.5474\n",
      "Epoch 29/5000\n",
      "0s - loss: 0.9459 - acc: 0.5758 - val_loss: 1.0075 - val_acc: 0.5469\n",
      "Epoch 30/5000\n",
      "0s - loss: 0.9450 - acc: 0.5769 - val_loss: 1.0082 - val_acc: 0.5482\n",
      "Epoch 31/5000\n",
      "0s - loss: 0.9486 - acc: 0.5735 - val_loss: 1.0079 - val_acc: 0.5480\n",
      "Epoch 32/5000\n",
      "0s - loss: 0.9460 - acc: 0.5765 - val_loss: 1.0080 - val_acc: 0.5482\n",
      "Epoch 33/5000\n",
      "0s - loss: 0.9453 - acc: 0.5764 - val_loss: 1.0079 - val_acc: 0.5477\n",
      "Epoch 34/5000\n",
      "0s - loss: 0.9451 - acc: 0.5784 - val_loss: 1.0086 - val_acc: 0.5481\n",
      "Epoch 35/5000\n",
      "0s - loss: 0.9452 - acc: 0.5762 - val_loss: 1.0079 - val_acc: 0.5475\n",
      "Epoch 36/5000\n",
      "0s - loss: 0.9458 - acc: 0.5762 - val_loss: 1.0081 - val_acc: 0.5478\n",
      "Epoch 37/5000\n",
      "0s - loss: 0.9470 - acc: 0.5743 - val_loss: 1.0081 - val_acc: 0.5480\n",
      "Epoch 38/5000\n",
      "0s - loss: 0.9429 - acc: 0.5769 - val_loss: 1.0080 - val_acc: 0.5478\n",
      "Epoch 39/5000\n",
      "0s - loss: 0.9443 - acc: 0.5769 - val_loss: 1.0081 - val_acc: 0.5478\n",
      "Epoch 40/5000\n",
      "0s - loss: 0.9467 - acc: 0.5772 - val_loss: 1.0082 - val_acc: 0.5479\n",
      "Epoch 41/5000\n",
      "0s - loss: 0.9445 - acc: 0.5789 - val_loss: 1.0083 - val_acc: 0.5477\n",
      "Epoch 42/5000\n",
      "0s - loss: 0.9447 - acc: 0.5777 - val_loss: 1.0084 - val_acc: 0.5472\n",
      "Epoch 43/5000\n",
      "0s - loss: 0.9458 - acc: 0.5768 - val_loss: 1.0084 - val_acc: 0.5478\n",
      "Epoch 44/5000\n",
      "0s - loss: 0.9453 - acc: 0.5758 - val_loss: 1.0086 - val_acc: 0.5475\n",
      "Epoch 45/5000\n",
      "0s - loss: 0.9445 - acc: 0.5770 - val_loss: 1.0084 - val_acc: 0.5474\n",
      "Epoch 46/5000\n",
      "0s - loss: 0.9452 - acc: 0.5764 - val_loss: 1.0087 - val_acc: 0.5475\n",
      "Epoch 47/5000\n",
      "0s - loss: 0.9455 - acc: 0.5782 - val_loss: 1.0086 - val_acc: 0.5468\n",
      "Epoch 48/5000\n",
      "0s - loss: 0.9431 - acc: 0.5771 - val_loss: 1.0085 - val_acc: 0.5470\n",
      "Epoch 49/5000\n",
      "0s - loss: 0.9445 - acc: 0.5777 - val_loss: 1.0086 - val_acc: 0.5475\n",
      "Epoch 50/5000\n",
      "0s - loss: 0.9426 - acc: 0.5782 - val_loss: 1.0084 - val_acc: 0.5477\n",
      "Epoch 51/5000\n",
      "0s - loss: 0.9448 - acc: 0.5761 - val_loss: 1.0084 - val_acc: 0.5479\n",
      "Epoch 52/5000\n",
      "0s - loss: 0.9435 - acc: 0.5761 - val_loss: 1.0086 - val_acc: 0.5479\n",
      "Epoch 53/5000\n",
      "0s - loss: 0.9434 - acc: 0.5756 - val_loss: 1.0087 - val_acc: 0.5480\n",
      "Epoch 54/5000\n",
      "0s - loss: 0.9419 - acc: 0.5768 - val_loss: 1.0088 - val_acc: 0.5477\n",
      "Epoch 55/5000\n",
      "0s - loss: 0.9431 - acc: 0.5770 - val_loss: 1.0092 - val_acc: 0.5467\n",
      "Epoch 56/5000\n",
      "0s - loss: 0.9440 - acc: 0.5763 - val_loss: 1.0087 - val_acc: 0.5465\n",
      "Epoch 57/5000\n",
      "0s - loss: 0.9413 - acc: 0.5762 - val_loss: 1.0087 - val_acc: 0.5470\n",
      "Epoch 58/5000\n",
      "0s - loss: 0.9421 - acc: 0.5779 - val_loss: 1.0087 - val_acc: 0.5482\n",
      "Epoch 59/5000\n",
      "0s - loss: 0.9433 - acc: 0.5767 - val_loss: 1.0087 - val_acc: 0.5482\n",
      "Epoch 60/5000\n",
      "0s - loss: 0.9401 - acc: 0.5785 - val_loss: 1.0089 - val_acc: 0.5479\n",
      "Epoch 61/5000\n",
      "0s - loss: 0.9427 - acc: 0.5781 - val_loss: 1.0088 - val_acc: 0.5472\n",
      "Epoch 62/5000\n",
      "0s - loss: 0.9430 - acc: 0.5782 - val_loss: 1.0093 - val_acc: 0.5472\n",
      "Epoch 63/5000\n",
      "0s - loss: 0.9422 - acc: 0.5772 - val_loss: 1.0091 - val_acc: 0.5474\n",
      "Epoch 64/5000\n",
      "0s - loss: 0.9415 - acc: 0.5786 - val_loss: 1.0089 - val_acc: 0.5478\n",
      "Epoch 65/5000\n",
      "0s - loss: 0.9404 - acc: 0.5776 - val_loss: 1.0089 - val_acc: 0.5470\n",
      "Epoch 66/5000\n",
      "0s - loss: 0.9407 - acc: 0.5789 - val_loss: 1.0090 - val_acc: 0.5469\n",
      "Epoch 67/5000\n",
      "0s - loss: 0.9413 - acc: 0.5771 - val_loss: 1.0089 - val_acc: 0.5477\n",
      "Epoch 68/5000\n",
      "0s - loss: 0.9417 - acc: 0.5778 - val_loss: 1.0096 - val_acc: 0.5481\n",
      "Epoch 69/5000\n",
      "0s - loss: 0.9393 - acc: 0.5797 - val_loss: 1.0090 - val_acc: 0.5472\n",
      "Epoch 70/5000\n",
      "0s - loss: 0.9400 - acc: 0.5793 - val_loss: 1.0095 - val_acc: 0.5472\n",
      "Epoch 71/5000\n",
      "0s - loss: 0.9401 - acc: 0.5788 - val_loss: 1.0092 - val_acc: 0.5468\n",
      "Epoch 72/5000\n",
      "0s - loss: 0.9423 - acc: 0.5766 - val_loss: 1.0094 - val_acc: 0.5475\n",
      "Epoch 73/5000\n",
      "0s - loss: 0.9407 - acc: 0.5790 - val_loss: 1.0094 - val_acc: 0.5481\n",
      "Epoch 74/5000\n",
      "0s - loss: 0.9412 - acc: 0.5779 - val_loss: 1.0096 - val_acc: 0.5480\n",
      "Epoch 75/5000\n",
      "0s - loss: 0.9416 - acc: 0.5757 - val_loss: 1.0094 - val_acc: 0.5477\n",
      "Epoch 76/5000\n",
      "0s - loss: 0.9403 - acc: 0.5788 - val_loss: 1.0095 - val_acc: 0.5475\n",
      "Epoch 77/5000\n",
      "0s - loss: 0.9393 - acc: 0.5773 - val_loss: 1.0094 - val_acc: 0.5479\n",
      "Epoch 78/5000\n",
      "0s - loss: 0.9417 - acc: 0.5787 - val_loss: 1.0094 - val_acc: 0.5477\n",
      "Epoch 79/5000\n",
      "0s - loss: 0.9404 - acc: 0.5792 - val_loss: 1.0099 - val_acc: 0.5480\n",
      "Epoch 80/5000\n",
      "0s - loss: 0.9392 - acc: 0.5799 - val_loss: 1.0094 - val_acc: 0.5470\n",
      "Epoch 81/5000\n",
      "0s - loss: 0.9374 - acc: 0.5796 - val_loss: 1.0102 - val_acc: 0.5483\n",
      "Epoch 82/5000\n",
      "0s - loss: 0.9399 - acc: 0.5790 - val_loss: 1.0099 - val_acc: 0.5480\n",
      "Epoch 83/5000\n",
      "0s - loss: 0.9394 - acc: 0.5756 - val_loss: 1.0096 - val_acc: 0.5480\n",
      "Epoch 84/5000\n",
      "0s - loss: 0.9381 - acc: 0.5793 - val_loss: 1.0098 - val_acc: 0.5479\n",
      "Epoch 85/5000\n",
      "0s - loss: 0.9401 - acc: 0.5778 - val_loss: 1.0096 - val_acc: 0.5468\n",
      "Epoch 86/5000\n",
      "0s - loss: 0.9373 - acc: 0.5803 - val_loss: 1.0095 - val_acc: 0.5473\n",
      "Epoch 87/5000\n",
      "0s - loss: 0.9389 - acc: 0.5794 - val_loss: 1.0094 - val_acc: 0.5473\n",
      "Epoch 88/5000\n",
      "0s - loss: 0.9382 - acc: 0.5793 - val_loss: 1.0097 - val_acc: 0.5471\n",
      "Epoch 89/5000\n",
      "0s - loss: 0.9388 - acc: 0.5797 - val_loss: 1.0099 - val_acc: 0.5481\n",
      "Epoch 90/5000\n",
      "0s - loss: 0.9393 - acc: 0.5786 - val_loss: 1.0103 - val_acc: 0.5478\n",
      "Epoch 91/5000\n",
      "0s - loss: 0.9382 - acc: 0.5812 - val_loss: 1.0102 - val_acc: 0.5477\n",
      "Epoch 92/5000\n",
      "0s - loss: 0.9414 - acc: 0.5799 - val_loss: 1.0098 - val_acc: 0.5469\n",
      "Epoch 93/5000\n",
      "0s - loss: 0.9380 - acc: 0.5789 - val_loss: 1.0097 - val_acc: 0.5475\n",
      "Epoch 94/5000\n",
      "0s - loss: 0.9377 - acc: 0.5805 - val_loss: 1.0102 - val_acc: 0.5479\n",
      "Epoch 95/5000\n",
      "0s - loss: 0.9373 - acc: 0.5799 - val_loss: 1.0099 - val_acc: 0.5475\n",
      "Epoch 96/5000\n",
      "0s - loss: 0.9375 - acc: 0.5815 - val_loss: 1.0102 - val_acc: 0.5483\n",
      "Epoch 97/5000\n",
      "0s - loss: 0.9394 - acc: 0.5777 - val_loss: 1.0099 - val_acc: 0.5478\n",
      "Epoch 98/5000\n",
      "0s - loss: 0.9352 - acc: 0.5807 - val_loss: 1.0106 - val_acc: 0.5480\n",
      "Epoch 99/5000\n",
      "0s - loss: 0.9398 - acc: 0.5788 - val_loss: 1.0104 - val_acc: 0.5477\n",
      "Epoch 100/5000\n",
      "0s - loss: 0.9382 - acc: 0.5807 - val_loss: 1.0105 - val_acc: 0.5473\n",
      "Epoch 101/5000\n",
      "0s - loss: 0.9392 - acc: 0.5786 - val_loss: 1.0106 - val_acc: 0.5473\n",
      "Epoch 102/5000\n",
      "0s - loss: 0.9396 - acc: 0.5797 - val_loss: 1.0103 - val_acc: 0.5467\n",
      "Epoch 103/5000\n",
      "0s - loss: 0.9377 - acc: 0.5798 - val_loss: 1.0106 - val_acc: 0.5477\n",
      "Epoch 104/5000\n",
      "0s - loss: 0.9362 - acc: 0.5795 - val_loss: 1.0105 - val_acc: 0.5470\n",
      "Epoch 105/5000\n",
      "0s - loss: 0.9374 - acc: 0.5809 - val_loss: 1.0109 - val_acc: 0.5475\n",
      "Epoch 106/5000\n",
      "0s - loss: 0.9370 - acc: 0.5818 - val_loss: 1.0101 - val_acc: 0.5460\n",
      "Epoch 107/5000\n",
      "0s - loss: 0.9349 - acc: 0.5803 - val_loss: 1.0109 - val_acc: 0.5471\n",
      "Epoch 108/5000\n",
      "0s - loss: 0.9361 - acc: 0.5816 - val_loss: 1.0102 - val_acc: 0.5474\n",
      "Epoch 109/5000\n",
      "0s - loss: 0.9345 - acc: 0.5804 - val_loss: 1.0108 - val_acc: 0.5475\n",
      "Epoch 110/5000\n",
      "0s - loss: 0.9342 - acc: 0.5790 - val_loss: 1.0108 - val_acc: 0.5482\n",
      "Epoch 111/5000\n",
      "0s - loss: 0.9370 - acc: 0.5815 - val_loss: 1.0106 - val_acc: 0.5478\n",
      "Epoch 112/5000\n",
      "0s - loss: 0.9344 - acc: 0.5823 - val_loss: 1.0113 - val_acc: 0.5480\n",
      "Epoch 113/5000\n",
      "0s - loss: 0.9374 - acc: 0.5797 - val_loss: 1.0107 - val_acc: 0.5476\n",
      "Epoch 114/5000\n",
      "0s - loss: 0.9372 - acc: 0.5791 - val_loss: 1.0113 - val_acc: 0.5483\n",
      "Epoch 115/5000\n",
      "0s - loss: 0.9363 - acc: 0.5786 - val_loss: 1.0107 - val_acc: 0.5479\n",
      "Epoch 116/5000\n",
      "0s - loss: 0.9372 - acc: 0.5798 - val_loss: 1.0110 - val_acc: 0.5477\n",
      "Epoch 117/5000\n",
      "0s - loss: 0.9350 - acc: 0.5809 - val_loss: 1.0108 - val_acc: 0.5478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25e4a47198>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=20000, \n",
    "          nb_epoch=5000,\n",
    "          verbose=2, \n",
    "          validation_split=0.33,\n",
    "          callbacks=[EarlyStopping(monitor='val_acc', patience=100, mode='max')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Sentiment\n",
      "0   0          5\n",
      "1   1          3\n",
      "2   2          5\n",
      "3   3          5\n",
      "4   4          4\n"
     ]
    }
   ],
   "source": [
    "pred_test = [list(x).index(max(x)) for x in model.predict(X_test)]\n",
    "prediction = pd.DataFrame(data={'Id': test.Id, 'Sentiment': pred_test}, index=test.index)\n",
    "prediction.to_csv('data/prediction.csv', index=False)\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
