{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "ENCODING = \"utf-8\"\n",
    "\n",
    "# train settings\n",
    "TRAIN_FPATH = \"train-bel.txt\"\n",
    "TRAIN_RELPATH = os.path.join(DATA_PATH, TRAIN_FPATH)\n",
    "\n",
    "# test settings\n",
    "TEST_FPATH = \"test-bel.txt\"\n",
    "TEST_RELPATH = os.path.join(DATA_PATH, TEST_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fpath, encoding=ENCODING):\n",
    "    # type: (str, str) -> List[str]\n",
    "    \n",
    "    file = codecs.open(fpath, \"r\", encoding=encoding)\n",
    "    sentences = [_.strip() for _ in file if _.strip()]\n",
    "    return sentences\n",
    "\n",
    "train = read_data(TRAIN_RELPATH)\n",
    "test = read_data(TEST_RELPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Заведзеная крымінальная справа па артыкуле «Забойства, здзейсненае агульнанебяспечным спосабам». Падазраванаму можа пагражаць турэмны тэрмін аж да пажыццёвага пазбаўлення волі.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 200000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _unspace_sentence(sentence):\n",
    "    # type: (str) -> str\n",
    "    \n",
    "    return re.sub(\" \", \"\", sentence)\n",
    "\n",
    "\n",
    "def _transform_sentence(sentence):\n",
    "    # type: (str) -> str\n",
    "    \n",
    "    tokens = []\n",
    "    for s in sentence:\n",
    "        if s.isspace():\n",
    "            tokens[-1] = 1\n",
    "        else:\n",
    "            tokens.append(0)\n",
    "    \n",
    "    tokens = \"\".join(map(str, tokens))\n",
    "    unspace_sent = _unspace_sentence(sentence)\n",
    "    \n",
    "    assert(len(unspace_sent) == len(tokens))\n",
    "    \n",
    "    return unspace_sent, tokens\n",
    "\n",
    "\n",
    "def transform_data(dataset):\n",
    "    # type: (List[str]) -> List[str]\n",
    "    \n",
    "    return list(map(_transform_sentence, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transform_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Першаязгэтыхпраблемаўсфармуляванаятак:',\n",
       " '00000110000100000000100000000000010000')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_symbol_set = set(codecs.open(\"data/train-bel.txt\", \"r\", encoding=\"utf-8\").read())\n",
    "test_symbol_set = set(codecs.open(\"data/test-bel.txt\", \"r\", encoding=\"utf-8\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 322)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_symbol_set), len(test_symbol_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296, 429)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_symbol_set & test_symbol_set), len(train_symbol_set | test_symbol_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\x97',\n",
       " '÷',\n",
       " 'ǝ',\n",
       " 'ɔ',\n",
       " 'ʁ',\n",
       " 'ʏ',\n",
       " '̀',\n",
       " 'Ѳ',\n",
       " 'י',\n",
       " 'כ',\n",
       " 'ל',\n",
       " 'מ',\n",
       " 'ר',\n",
       " 'ת',\n",
       " 'ب',\n",
       " 'ت',\n",
       " 'د',\n",
       " 'ر',\n",
       " 'م',\n",
       " 'و',\n",
       " 'ي',\n",
       " '‐',\n",
       " '‒',\n",
       " '≠',\n",
       " '⬇',\n",
       " '￼'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_symbol_set - train_symbol_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
