{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename='data/train.csv'):\n",
    "    return pd.read_csv(filename, encoding='utf-8', dialect='excel', lineterminator='\\n')\n",
    "\n",
    "\n",
    "def read_test(filename='data/test.csv'):\n",
    "    return pd.read_csv(filename, encoding='utf-8', dialect='excel', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    @staticmethod\n",
    "    def get_user_lang_feature(data, train_data):\n",
    "        table = train_data[['user.lang', 'retweet_count']].groupby(by='user.lang').mean()\n",
    "        table = table.to_dict()['retweet_count']\n",
    "        return pd.Series.from_array([table.get(x, np.mean(list(table.values()))) for x in data['user.lang']])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_text_feature(data, i):\n",
    "        if i == 0:\n",
    "            return pd.Series.from_array([x.count('http') for x in data['text']])\n",
    "        elif i == 1:\n",
    "            return pd.Series.from_array([x.count('@') for x in data['text']])\n",
    "        elif i == 2:\n",
    "            return pd.Series.from_array([x.count('#') for x in data['text']])\n",
    "        elif i == 3:\n",
    "            return pd.Series.from_array([len(x.split()) for x in data['text']])\n",
    "        elif i == 4:\n",
    "            return pd.Series.from_array([x.count('?') for x in data['text']])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_in_reply_to_user_id_feature(data):\n",
    "        return pd.Series.from_array([np.bool(x) for x in data['in_reply_to_user_id']])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_user_description_feature(data, i):\n",
    "        if i == 0:\n",
    "            return pd.Series.from_array([x.count('http') for x in data['text']])\n",
    "        elif i == 1:\n",
    "            return pd.Series.from_array([x.count('@') for x in data['text']])\n",
    "        elif i == 2:\n",
    "            return pd.Series.from_array([x.count('#') for x in data['text']])\n",
    "        elif i == 3:\n",
    "            return pd.Series.from_array([len(x.split()) for x in data['text']])\n",
    "        elif i == 4:\n",
    "            return pd.Series.from_array([x.count('?') for x in data['text']])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_user_time_zone_feature(data, train_data):\n",
    "        table = train_data[['user.time_zone', 'retweet_count']].groupby(by='user.time_zone').mean()\n",
    "        table = table.to_dict()['retweet_count']\n",
    "        return pd.Series.from_array([table.get(x, np.mean(list(table.values()))) for x in data['user.time_zone']])\n",
    "\n",
    "\n",
    "def df2features(data, train_data):\n",
    "    return np.array([\n",
    "        Features.get_text_feature(data, 0),\n",
    "        Features.get_text_feature(data, 1),\n",
    "        Features.get_text_feature(data, 2),\n",
    "        Features.get_text_feature(data, 3),\n",
    "        Features.get_text_feature(data, 4),\n",
    "        data['in_reply_to_user_id'],\n",
    "        Features.get_user_description_feature(data, 0),\n",
    "        Features.get_user_description_feature(data, 1),\n",
    "        Features.get_user_description_feature(data, 2),\n",
    "        Features.get_user_description_feature(data, 3),\n",
    "        Features.get_user_description_feature(data, 4),\n",
    "        Features.get_user_lang_feature(data, train_data),\n",
    "        Features.get_user_time_zone_feature(data, train_data),\n",
    "        data['user.utc_offset'],\n",
    "        data['user.statuses_count'],\n",
    "        data['user.followers_count'],\n",
    "        data['user.friends_count'],\n",
    "        data['user.favourites_count'],\n",
    "        data['user.is_translation_enabled'],\n",
    "        data['user.geo_enabled'],\n",
    "        data['user.listed_count']\n",
    "    ]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    @staticmethod\n",
    "    def model(model, param_grid, train_X, test_X, train_y, test_y, real_test_X):\n",
    "        est = GridSearchCV(model, param_grid=param_grid, n_jobs=4)\n",
    "        est.fit(train_X, train_y)\n",
    "\n",
    "        proba_train = est.predict_proba(train_X)\n",
    "        print(roc_auc_score(train_y, proba_train[:, 1]))\n",
    "\n",
    "        proba_test = est.predict_proba(test_X)\n",
    "        print(roc_auc_score(test_y, proba_test[:, 1]))\n",
    "\n",
    "        proba_real_test = est.predict_proba(real_test_X)\n",
    "        return proba_train[:, 1], proba_test[:, 1], proba_real_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, test_data = read_train(), read_test()\n",
    "data_y = data['retweet_count'] > 20\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, data_y, test_size=0.33)\n",
    "train_X, test_X, real_test_X = df2features(train_X, train_X), \\\n",
    "                               df2features(test_X, train_X), df2features(test_data, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01530391  0.02063559  0.02066867  0.06398109  0.0079293   0.01864598\n  0.0172736   0.02019353  0.02170001  0.06350632  0.00787501  0.00899759\n  0.04646124  0.04179874  0.07963917  0.18212388  0.06911849  0.07183471\n  0.04342892  0.01896239  0.15992187]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, proba = Models.model(RandomForestClassifier(), {'n_estimators': [i for i in range(80, 250, 30)],\n",
    "                                                      'criterion':  ['gini', 'entropy'], \n",
    "                                                      'min_samples_leaf': [i for i in range(5, 101, 10)]}, \n",
    "                           train_X, test_X, train_y, test_y, real_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931354731834\n0.920695873928\n"
     ]
    }
   ],
   "source": [
    "_, _, proba2 = Models.model(GradientBoostingClassifier(), {'n_estimators': [i for i in range(80, 250, 30)],\n",
    "                                                           'criterion': ['friedman_mse', 'mse'],\n",
    "                                                           'min_samples_leaf': [i for i in range(5, 101, 10)]},\n",
    "                            train_X, test_X, train_y, test_y, real_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, proba3 = Models.model(SVC(probability=True, verbose=True), {'kernel': ['poly', 'rbf']}, \n",
    "                      train_X, test_X, train_y, test_y, real_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id  probability\n0  629692042952765440     0.003357\n1  629692042717855745     0.002738\n2  629692039974813696     0.003716\n3  629692038242566145     0.793212\n4  629692036879413248     0.004685\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(data={'id': test_data['id'], 'probability': proba2})\n",
    "prediction.to_csv('data/prediction.csv', index=False)\n",
    "print(prediction.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}