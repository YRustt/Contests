{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename='data/train.csv'):\n",
    "    return pd.read_csv(filename, encoding='utf-8', dialect='excel', lineterminator='\\n')\n",
    "\n",
    "\n",
    "def read_test(filename='data/test.csv'):\n",
    "    return pd.read_csv(filename, encoding='utf-8', dialect='excel', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    @staticmethod\n",
    "    def get_user_lang_feature(data, train_data):\n",
    "        table = train_data[['user.lang', 'retweet_count']].groupby(by='user.lang').mean()\n",
    "        table = table.to_dict()['retweet_count']\n",
    "        return pd.Series.from_array([table.get(x, np.mean(list(table.values()))) for x in data['user.lang']])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_text_feature(data, i):\n",
    "        if i == 0:\n",
    "            return pd.Series.from_array([x.count('http') for x in data['text']])\n",
    "        elif i == 1:\n",
    "            return pd.Series.from_array([x.count('@') for x in data['text']])\n",
    "        elif i == 2:\n",
    "            return pd.Series.from_array([x.count('#') for x in data['text']])\n",
    "        elif i == 3:\n",
    "            return pd.Series.from_array([len(x.split()) for x in data['text']])\n",
    "        elif i == 4:\n",
    "            return pd.Series.from_array([x.count('?') for x in data['text']])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_in_reply_to_user_id_feature(data):\n",
    "        return pd.Series.from_array([np.bool(x) for x in data['in_reply_to_user_id']])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_user_time_zone_feature(data, train_data):\n",
    "        table = train_data[['user.time_zone', 'retweet_count']].groupby(by='user.time_zone').mean()\n",
    "        table = table.to_dict()['retweet_count']\n",
    "        return pd.Series.from_array([table.get(x, np.mean(list(table.values()))) for x in data['user.time_zone']])\n",
    "\n",
    "\n",
    "def df2features(data, train_data):\n",
    "    return np.array([\n",
    "        Features.get_text_feature(data, 0),\n",
    "        Features.get_text_feature(data, 1),\n",
    "        Features.get_text_feature(data, 2),\n",
    "        Features.get_text_feature(data, 3),\n",
    "        Features.get_in_reply_to_user_id_feature(data),\n",
    "        Features.get_user_lang_feature(data, train_data),\n",
    "        Features.get_user_time_zone_feature(data, train_data),\n",
    "        data['user.utc_offset'],\n",
    "        data['user.statuses_count'],\n",
    "        data['user.followers_count'],\n",
    "        data['user.friends_count'],\n",
    "        data['user.favourites_count'],\n",
    "        data['user.is_translation_enabled'],\n",
    "        data['user.geo_enabled'],\n",
    "        data['user.listed_count']\n",
    "    ]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    @staticmethod\n",
    "    def model(model, param_grid, train_X, test_X, train_y, test_y, real_test_X):\n",
    "        est = GridSearchCV(model, param_grid=param_grid, n_jobs=4)\n",
    "        est.fit(train_X, train_y)\n",
    "\n",
    "        proba = est.predict_proba(train_X)\n",
    "        print(roc_auc_score(train_y, proba[:, 1]))\n",
    "\n",
    "        proba = est.predict_proba(test_X)\n",
    "        print(roc_auc_score(test_y, proba[:, 1]))\n",
    "\n",
    "        proba = est.predict_proba(real_test_X)\n",
    "        return proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, test_data = read_train(), read_test()\n",
    "data_y = data['retweet_count'] > 20\n",
    "train_X, test_X, train_y, test_y = train_test_split(data, data_y, test_size=0.33)\n",
    "train_X, test_X, real_test_X = df2features(train_X, train_X), \\\n",
    "                               df2features(test_X, train_X), df2features(test_data, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03429545  0.03609091  0.03460692  0.12264179  0.03219169  0.00805142\n  0.04590907  0.04324756  0.08175415  0.19382682  0.06987422  0.07257279\n  0.04031965  0.01621531  0.16840225]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(train_X, train_y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.984412240336\n0.92602674753\n"
     ]
    }
   ],
   "source": [
    "proba = Models.model(RandomForestClassifier(), {'criterion':  ['gini', 'entropy'], \n",
    "                                                'min_samples_leaf': [i for i in range(5, 101, 5)]}, \n",
    "                     train_X, test_X, train_y, test_y, real_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proba2 = Models.model(SVC(probability=True, verbose=True), {'kernel': ['poly', 'rbf']}, \n",
    "#                       train_X, test_X, train_y, test_y, real_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id  probability\n0  629692042952765440     0.000000\n1  629692042717855745     0.000000\n2  629692039974813696     0.000000\n3  629692038242566145     0.619466\n4  629692036879413248     0.000000\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(data={'id': test_data['id'], 'probability': proba})\n",
    "prediction.to_csv('data/prediction.csv', index=False)\n",
    "print(prediction.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}